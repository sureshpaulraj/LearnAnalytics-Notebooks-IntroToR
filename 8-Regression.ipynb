{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "In this module, we will explore how to do regression analyses with R.\n",
    "\n",
    "If you are unfamiliar with notebooks, please review some basics [here](https://github.com/michhar/useR2016-tutorial-jupyter). \n",
    "\n",
    "## Essential Tips\n",
    "\n",
    "A very brief summary of the critical components and commands within jupyter are:\n",
    "\n",
    "1. Critically, press `Ctrl+Enter` to run (or render) the current cell.\n",
    "2. Output will print to the notebook. You may have to scroll up to see it all.\n",
    "3. Get help for any function by typing a question mark and then its name into\n",
    "   the console: `?rxLinMod`. It will split the window, and will bring up the documentation for \n",
    "   that function below.\n",
    "5. Files will appear in the specified directory. You can find them by selecting File in the menu bar and selecting \"Open...\". This will open a new browser window with a file navigator.\n",
    "6. R objects can be viewed by typing `ls()` in an R cell.\n",
    "7. Run all the example code!\n",
    "\n",
    "There are a number of hands-on exercises in the document, so while you can run the notebook from beginning to end, you will get a lot more out of it by actually walking through cell-by-cell, and filling out the corresponding exercises.\n",
    "\n",
    "These notebooks are based on a tutorial presented at a Microsoft conference in June of 2016. The original files are available [here](https://github.com/joseph-rickert/MLADS_JUNE_2016).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis\n",
    "\n",
    "This module takes you through the process of fitting a multiple regression model. \n",
    "\n",
    "The data come from the UCI machine Learning Repository. The data are described here:\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.names, and here: http://cs.nyu.edu/courses/fall00/G22.3033-001/weka/weka-3-0-2/data/auto-mpg.arff\n",
    "\n",
    "### Setup  \n",
    "Before we get started, we'll source a configuration file in the next cell. It simply makes sure that the relevant R packages and datasets are available. You do not need to look at it, but if you are interested, you can view the configuration file [here](Resources/config.R). It may take a few moments to run the first time you run it, but it should be fast afterwards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source(\"Resources/config.R\")\n",
    "source(\"Resources/splitData.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "Let's start by getting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir <- 'data'\n",
    "mpg_file <- file.path(data_dir,'mpg_orig.csv')\n",
    "file.remove(mpg_file)\n",
    "if(file.exists(mpg_file)){\n",
    "    cat('*** Reading mpg file from local file.\\n')\n",
    "    mpg <- read.csv(mpg_file)\n",
    "}else{\n",
    "    cat('*** Reading mpg file from remote url.\\n')\n",
    "    url <-\"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\"\n",
    "    mpg <- read.table(url,na.strings=\"?\")\n",
    "    names(mpg) <- c(\"mpg\",\"cyl\",\"disp\",\"hp\",\"weight\",\"accel\",\"year\",\"origin\",\"name\")\n",
    "    cat('*** Saving mpg file for posterity.\\n')\n",
    "    write.csv(mpg,file = mpg_file,row.names=FALSE)\n",
    "    mpg <- read.csv(mpg_file, header = TRUE)\n",
    "}\n",
    "head(mpg)\n",
    "dim(mpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's start by seeing how many missing values there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(is.na(mpg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do something about those\n",
    "\n",
    "Let's remove the missing values since there are only six of them. In another context, you would potentially consider imputing the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpg <- na.omit(mpg)  ## remember this deletes the entire row!\n",
    "dim(mpg)\n",
    "sum(is.na(mpg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the data\n",
    "\n",
    "Let's summarize the data first. First explore the class of each variable and then get univariate statistics for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sapply(mpg,class)\n",
    "summary(mpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coerce our variables\n",
    "\n",
    "Next, it actually makes sense to create some categorical variables. For instance, we may care about the origin of the car as a categorical variable, we may want to use year as a categorical variable, and we may want to use cyl as a categorical variable. They are all numbers, but there is no strong reason to expect purely linear relationships between those variables and the outcome. \n",
    "\n",
    "In particular, if we look at the links above, we can also attach semantic labels to our origin variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "mpg <- mutate(mpg, cyl = as.factor(cyl),\n",
    "              year = as.factor(year),\n",
    "              origin = factor(origin, labels = c('USA','Europe','Japan')))\n",
    "sapply(mpg,class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "In this section we look at numerical summaries of the data as well as various plots to visualize relationships among the variables.\n",
    "\n",
    "First, let's rerun the summary now that we have some categorical variables defined as such. We'll note that the factor variables end up producing frequency counts rather than arithmetic summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(dplyr::select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at correlations among the numeric variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_vars <- names(mpg)[sapply(mpg, is.numeric)]\n",
    "num_vars\n",
    "mpg_num <- select(mpg, one_of(num_vars))\n",
    "cor(mpg_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(corrplot)\n",
    "corrplot(cor(mpg_num), method=\"ellipse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the at pairwise relationships for continuous variables\n",
    "\n",
    "While `corrplot()` is an easy way to visually represent those relationships, we can also do some more sophisticated pieces with the `pairs()` function. It includes arguments where you can customize the panels to plot additional information.\n",
    "\n",
    "THe `panel` argument in this case allows us to plot points and the best fitting OLS regression line, and the `diag.panel` argument allows us to simply provide a histogram of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs(mpg[,num_vars],          \n",
    "      panel=function(x,y){              \n",
    "        points(x,y, col=\"light blue\")   \n",
    "        abline(lm(y~x), lty=2,col=\"red\") \n",
    "      },\n",
    "      diag.panel=function(x){           \n",
    "        par(new=T)\n",
    "        hist(x,main=\"\",axes=F,nclass=12) \n",
    "      }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Graphics\n",
    "\n",
    "As we investigate more, we can see that there are some non-linear relationships, and we can also explore how some of the numeric variables are related to some of the continuous ones. In order to examine the categorical variables, let's use ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "p1 <- ggplot(mpg, aes(x = cyl, y = mpg))\n",
    "p1 + geom_boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mpg as a function of origin location\n",
    "p2 <- ggplot(mpg, aes(x = origin, y = mpg))\n",
    "p2 + geom_boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's color code according to origin, but plot two continous.\n",
    "p3 <- ggplot(mpg, aes(x = weight, y = mpg,col=origin))\n",
    "p3 + geom_point() + geom_smooth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mpg by year\n",
    "p4 <- ggplot(mpg, aes(x = year, y =mpg))\n",
    "p4 + geom_boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Regression Models\n",
    "\n",
    "In this section we divide randomly divide the data into training and test sets and then fit several regression models to the training data. Holding out some data enables us to assess the performance of these models by seeing how well they predict `mpg` for the test data. This kind of process is essential if you want to get an idea of how well the model will perform on data that it hasn't seen before. \n",
    "\n",
    "The function, `splitData()`, which is given above randomly splits the mpg data into two subsets: train and test. `mpg[ins$train,]` means index into the mpg data and return all of the columns of mpg but only the rows to be used for training the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "ind <- splitData(mpg)  # Split the mpg data into training and test data.\n",
    "lapply(ind, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by just using the numeric variables.\n",
    "\n",
    "We can construct the model specification programmatically by creating a formula. In this case, we only want the numeric variables (contained within `num_vars`), and we only want to consider their main effects, so we construct a formula with `+` separating the predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "form.1chr <- paste(\"mpg ~\", paste(num_vars[-1], collapse = '+'))\n",
    "form.1 <- formula(form.1chr)\n",
    "form.1                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit and summarize the model:\n",
    "lm.fit.1  <- lm(formula=form.1, data=mpg[ind$train,])   # Build the model\n",
    "summary(lm.fit.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "Let's add the number of cylinders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "form.2chr <- paste(form.1chr, 'cyl', sep = '+')\n",
    "form.2 <- formula(form.2chr)\n",
    "form.2\n",
    "lm.fit.2  <- lm(formula=form.2,data=mpg[ind$train,])   # Build the model\n",
    "summary(lm.fit.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3\n",
    "\n",
    "The third model looks at the effect of year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "form.3chr <- paste(form.2chr, 'year', sep = '+')\n",
    "form.3 <- formula(form.3chr)\n",
    "form.3\n",
    "lm.fit.3  <- lm(formula=form.3,data=mpg[ind$train,])   # Build the model\n",
    "summary(lm.fit.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4\n",
    "\n",
    "The fourth model looks at the effect of origin (but excludes year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "form.4chr <- paste(form.2chr, 'origin', sep = '+')\n",
    "form.4 <- formula(form.4chr)\n",
    "form.4\n",
    "lm.fit.4  <- lm(formula=form.4,data=mpg[ind$train,])   # Build the model\n",
    "summary(lm.fit.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5\n",
    "\n",
    "This model includes cyl, year, and origin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "form.5chr <- paste(form.4chr, 'year', sep = '+')\n",
    "form.5 <- formula(form.5chr)\n",
    "form.5\n",
    "lm.fit.5  <- lm(formula=form.5,data=mpg[ind$train,])   # Build the model\n",
    "summary(lm.fit.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "Model 5 had the best adjusted R squared, but it also had hte most degrees of freedom. We can use the `anova()` function to compare nested models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anova(lm.fit.1, lm.fit.2, lm.fit.3, lm.fit.5)\n",
    "anova(lm.fit.1, lm.fit.2, lm.fit.4, lm.fit.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Diagnostics\n",
    "\n",
    "It looks like model 5 is the best, but we may want to evaluate the assumptions that are going into that inference. We also probably want to test on new data.\n",
    "\n",
    "In this section we create the standard model diagnostic plots to evaluate how well the model fits the assumptions underlying regressin models. Look here http://www.stat.columbia.edu/~martin/W2024/R7.pdf for some information on interpreting the diagnostic plots. Except for a few outliers flagged by by the plotting software everything looks pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the regression diagnostics\n",
    "par(mfrow=c(2,2)) # set up device so all graphs are on one device \n",
    "c <- plot(lm.fit.5)\n",
    "par(mfrow=c(1,1)) # move it back to one device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at the outliers flagged in the diagnostic plots\n",
    "outliers <- c(273, 321, 326, 382 ,389)\n",
    "mpg[outliers,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Model Performance\n",
    "\n",
    "Here we get an idea of how well the model will do on new data by using the predict function to \"score\" the new data set. We then plot the actual reported values of MPG against the values predicted by the regression with confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions <- predict(lm.fit.5, newdata = mpg[ind$test,],se.fit=TRUE,interval=\"prediction\")\n",
    "str(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a data frame to hold the predictions\n",
    "df <- data.frame(y = mpg[ind$test,]$mpg, predictions)\n",
    "head(df,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's create some more plots\n",
    "\n",
    "Let's plot predictions vs actuals in the test data set, where error bars correspond to the confidence interval provided by `predict()`, which by default is a 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?predict.lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "p5 <- ggplot(df, aes(x = y, y = fit.fit))\n",
    "p5 + geom_errorbar(aes(ymin = fit.lwr, ymax = fit.upr), width = .1) +\n",
    "  geom_point() + \n",
    "  geom_abline(intercept = 0, slope = 1, linetype=2) +\n",
    "  xlab(\"Reported MPG\") +\n",
    "  ylab(\"Predicted MPG\") +\n",
    "  ggtitle(\"95% CIs for Predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model looks pretty good! The 45 degree line, which indicates a perfect predictions, is mostly covered by the confidence intervals. \n",
    "\n",
    "For homework, try creating some more exploratory plots and building additional regression models. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "MR Client 3.2.2",
   "language": "R",
   "name": "irmrc32"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
