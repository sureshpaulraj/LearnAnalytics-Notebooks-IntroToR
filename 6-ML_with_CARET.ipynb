{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with CARET\n",
    "\n",
    "In this module, we will explore how to use the CARET package for doing machine learning.\n",
    "\n",
    "If you are unfamiliar with notebooks, please review some basics [here](https://github.com/michhar/useR2016-tutorial-jupyter). \n",
    "\n",
    "## Essential Tips\n",
    "\n",
    "A very brief summary of the critical components and commands within jupyter are:\n",
    "\n",
    "1. Critically, press `Ctrl+Enter` to run (or render) the current cell.\n",
    "2. Output will print to the notebook. You may have to scroll up to see it all.\n",
    "3. Get help for any function by typing a question mark and then its name into\n",
    "   the console: `?rxLinMod`. It will split the window, and will bring up the documentation for \n",
    "   that function below.\n",
    "5. Files will appear in the specified directory. You can find them by selecting File in the menu bar and selecting \"Open...\". This will open a new browser window with a file navigator.\n",
    "6. R objects can be viewed by typing `ls()` in an R cell.\n",
    "7. Run all the example code!\n",
    "\n",
    "There are a number of hands-on exercises in the document, so while you can run the notebook from beginning to end, you will get a lot more out of it by actually walking through cell-by-cell, and filling out the corresponding exercises.\n",
    "\n",
    "These notebooks are based on a tutorial presented at a Microsoft conference in June of 2016. The original files are available [here](https://github.com/joseph-rickert/MLADS_JUNE_2016).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "caret (short for **C**lassification **a**nd **RE**gression **T**raining) is the most feature rich package for doing machine learning in R. It provides functions to streamline the entire process and includes tools for:  \n",
    "\n",
    "* data splitting    \n",
    "* pre-processing    \n",
    "* feature selection    \n",
    "* model tuning using resampling    \n",
    "* variable importance estimation    \n",
    "\n",
    "This script explores caret's capabilities using a cell segmentation data set that is included in the package. The data is described in the paper: Hill et al \"Impact of image segmentation on high-content screening data quality for SK-BR-3 cells\" BMC fioinformatics (2007) vol 8 (1) pp. 340.\n",
    "\n",
    "The analysis presented here is based on examples presented by Max Kuhn, caret's author, at Use-R 2012.\n",
    "\n",
    "We covered this same dataset in our [Introduction to Classification](5-Classification.ipynb).\n",
    "\n",
    "Before we get started, we'll source a configuration file in the next cell. It simply makes sure that the relevant R packages and datasets are available. You do not need to look at it, but if you are interested, you can view the configuration file [here](Resources/config.R). It may take a few moments to run the first time you run it, but it should be fast afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source(\"Resources/config.R\")\n",
    "seed_val <- 1 # random seed value, to be actually set for the generator later\n",
    "set.seed(seed_val)   ## sets the random seed\n",
    "worker_seeds <- sample(1e7, size = 5)  ## used to set the seed for the worker nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "\"Well-segmented\" cells are cells for which location and size may be accurrately detremined through optical measurements. Cells that are not Well-segmented (WS) are said to be \"Poorly-segmented\"\" (PS). Given a set of optical measurements can we predict which cells will be PS? This is a classic classification problem.\n",
    "\n",
    "## Data\n",
    "\n",
    "We'll get started by loading the package, getting help on the dataset and loading the data using the `data()` function, and then viewing the first couple of rows.\n",
    "\n",
    "### Packages Required\n",
    "\n",
    "```{r}\n",
    "library(partykit)\t\t\t# Plotting trees\n",
    "library(rpart)  \t\t\t# CART algorithm for decision trees\n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "?segmentationData\n",
    "data(segmentationData)  \t# Load the segmentation data set\n",
    "dim(segmentationData)\n",
    "head(segmentationData,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CARET\n",
    "\n",
    "We haven't used CARET yet, other than to make the data accessible to R. The first function from CARET that we will leverage is `createDataPartition()`. This function allows us to create a partition of the data so that can split the data into training and testing sets explicitly and easily.\n",
    "\n",
    "Specifically, in the next case, we use `createDataPartition()` to create a vector of values that we then use to subset rows. The `p=.5` argument indicates that the vector will contain 50% of the entries in the entire dataset, and the `list=FALSE` indicates that it should return a vector of values, rather than a list with multiple sets of entries. Instead of using the list data structure, we use the negative indexing trick when we create `testData` to exclude anything in our training set.\n",
    "\n",
    "Our column indices are simply dropping the first two columns to make model specification simple (Note the use of negative indices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainIndex <- createDataPartition(segmentationData$Case,p=.5,list=FALSE) # create a vector of indices\n",
    "trainData <- segmentationData[trainIndex,-c(1,2)]  # create training data by using these as row indices.\n",
    "testData  <- segmentationData[-trainIndex,-c(1,2)] # create testing data by excluding training indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that 50% of data are in each case by looking at the number of rows in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(length(trainIndex) + nrow(testData)) == nrow(segmentationData)\n",
    "c(length(trainIndex), nrow(testData))/nrow(segmentationData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will remove the outcome variables so we have data frames with only the predictor variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX <-trainData[,-1]        # Pull out the dependent variable\n",
    "testX <- testData[,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERALIZED BOOSTED REGRESSION MODEL   \n",
    "\n",
    "We will start with building a generalized boosted regression model, or gbm. In order to do this, we need the gbm package, and we need to ntoe that the gbm function does not allow for categorical \"factor\" variables as dependent variables, so we will need to fix that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str(trainData$Class[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(gbm)\n",
    "gbmTrain <- trainData\n",
    "gbmTrain$Class <- ifelse(gbmTrain$Class==\"PS\",1,0) ## make this numeric\n",
    "gbm.mod <- gbm(formula = Class~.,  \t\t\t# use all variables\n",
    "\t\t\t\tdistribution = \"bernoulli\",\t\t  # for a classification problem\n",
    "\t\t\t\tdata = gbmTrain,\n",
    "\t\t\t\tn.trees = 2000,\t\t\t\t\t        # 2000 boosting iterations\n",
    "\t\t\t\tinteraction.depth = 7,\t\t\t    # 7 splits for each tree\n",
    "\t\t\t\tshrinkage = 0.01,\t\t\t\t        # the learning rate parameter\n",
    "\t\t\t\tverbose = FALSE)\t\t\t\t        # Do not print the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(gbm.mod)\t\t\t# Plot the relative inference of the variables in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interesting model, but how do you select the best values for the for the three tuning parameters?   \n",
    "\n",
    "* n.trees   \n",
    "* interaction.depth   \n",
    "* shrinkage   \n",
    "\n",
    "In turns out that this is where caret really shines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM Model Training Over Paramter Space\n",
    "\n",
    "`caret` provides the \"train\" function that implements the following algorithm: \n",
    "\n",
    "Algorithm for training the model:    \n",
    "Define sets of model parameters to evaluate    \n",
    "for each parameter set do    \n",
    "....for each resampling iteration do    \n",
    "......hold out specific samples     \n",
    "......pre-process the data    \n",
    "......fit the model to the remainder    \n",
    "....predict the holdout samples    \n",
    "....end      \n",
    "....calculate the average performance across hold-out predictions    \n",
    "end    \n",
    "Determine the optimal parameter set    \n",
    "Fit the final model to the training data using the optimal parameter set    \n",
    "\n",
    "Note the default method of picking the best model is accuracy and Cohen's $\\kappa$   \n",
    "\n",
    "Let's explore how this works in practice.\n",
    "\n",
    "## Set up training control\n",
    "\n",
    "First, we need to set up the data structure that will control the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctrl <- trainControl(method=\"repeatedcv\",   # 10fold cross validation\n",
    "\t\t\t\t\t repeats=5,\t\t\t\t\t\t\t          # do 5 repititions of cv\n",
    "\t\t\t\t\t summaryFunction=twoClassSummary,\t# Use AUC to pick the best model\n",
    "\t\t\t\t\t classProbs=TRUE,\n",
    "                    allowParallel = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define the parameter search space.\n",
    "\n",
    "We can use the `expand.grid()` function to help specify the search space efficiently.\n",
    "\n",
    "Note that the default search grid selects 3 values of each tuning parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid <- expand.grid(interaction.depth = seq(1,4,by=2), #tree depths from 1 to 4\n",
    "                    n.trees=seq(10,100,by=10),\t# let iterations go from 10 to 100\n",
    "                    shrinkage=c(0.01,0.1),\t\t\t# Try 2 values fornlearning rate \n",
    "                    n.minobsinnode = 20)\n",
    "set.seed(seed_val)                     # set the seed to 1 for sequential training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(pROC) \n",
    "system.time(gbm.tune <- train(x=trainX,y=trainData$Class,\n",
    "\t\t\t\tmethod = \"gbm\",\n",
    "\t\t\t\tmetric = \"ROC\",\n",
    "\t\t\t\ttrControl = ctrl,\n",
    "\t\t\t\ttuneGrid=grid,\n",
    "\t\t\t\tverbose=FALSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have the `doParallel` library installed, we can even ask CARET to do the parameter searches in parallel! \n",
    "\n",
    "This becomes a little complicated when combined with using packages that adjust your library location (or with using notebooks), but we'll address that as well.\n",
    "\n",
    "First, we just need to load doParallel and register the parallel back end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(doParallel)\n",
    "registerDoParallel(4)\t\t# Register a parallel backend for train\n",
    "getDoParWorkers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we run...\n",
    "\n",
    "We need to make sure that the workers spawned actually have the right path to packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shows that they're the default - We don't even have caret installed there!\n",
    "foreach(i = 1:getDoParWorkers()) %dopar% {.libPaths()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the current lps and make sure they're represented appropriately on the workers.\n",
    "current_lp <- .libPaths()\n",
    "foreach(i = 1:getDoParWorkers()) %dopar% {assign('.lib.loc', current_lp, envir = environment(.libPaths))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## show they're updated!\n",
    "foreach(i = 1:getDoParWorkers()) %dopar% {.libPaths()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "\n",
    "Because we're using a parallel backend now, we need to make sure the seeds in the backend are tracked for reproducibility sake. We can do that with a %dopar% call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set.seed(seed_val)   \n",
    "foreach(i = 1:getDoParWorkers()) %dopar% set.seed(worker_seeds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all we have to do is set the `allowParallel` value in `ctrl` to TRUE, and then rerun again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctrl$allowParallel <- TRUE\n",
    "system.time(gbm.tune <- train(x=trainX,y=trainData$Class,\n",
    "\t\t\t\tmethod = \"gbm\",\n",
    "\t\t\t\tmetric = \"ROC\",\n",
    "\t\t\t\ttrControl = ctrl,\n",
    "\t\t\t\ttuneGrid=grid,\n",
    "\t\t\t\tverbose=FALSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ends up being a bit faster in parallel (most of the time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the tuning results\n",
    "Note that ROC was the performance criterion used to select the optimal model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.tune$bestTune\n",
    "plot(gbm.tune)  \t\t# Plot the performance of the training models\n",
    "res <- gbm.tune$results\n",
    "names(res) <- c(\"depth\",\"trees\", \"shrinkage\",\"ROC\", \"Sens\",\"Spec\", \"sdROC\", \"sdSens\", \"seSpec\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM Model Predictions and Performance\n",
    "Make predictions using the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.pred <- predict(gbm.tune,testX)\n",
    "head(gbm.pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the confusion matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusionMatrix(gbm.pred,testData$Class)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the ROC curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.probs <- predict(gbm.tune,testX,type=\"prob\")\n",
    "head(gbm.probs)\n",
    "\n",
    "gbm.ROC <- roc(predictor=gbm.probs$PS,\n",
    "  \t\t\tresponse=testData$Class,\n",
    "\t\t\t\tlevels=rev(levels(testData$Class)))\n",
    "gbm.ROC\n",
    "\n",
    "plot(gbm.ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the propability of poor segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "histogram(~gbm.probs$PS|testData$Class,xlab=\"Probability of Poor Segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUPPORT VECTOR MACHINE MODEL \n",
    "We follow steps similar to those above to build a SVM model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up for parallel procerssing\n",
    "registerDoParallel(4,cores=4)\n",
    "getDoParWorkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sure libpaths are set, since we registered new ones\n",
    "foreach(i = 1:getDoParWorkers()) %dopar% {.libPaths()}\n",
    "foreach(i = 1:getDoParWorkers()) %dopar% {assign('.lib.loc', current_lp, envir = environment(.libPaths))}\n",
    "foreach(i = 1:getDoParWorkers()) %dopar% {.libPaths()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## We also need to set the seeds on the worker nodes:\n",
    "foreach(i = 1:getDoParWorkers()) %dopar% set.seed(worker_seeds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Tune the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctrl$allowParallel\n",
    "library(kernlab)\n",
    "set.seed(seed_val)# this will only matter if allowParallel = FALSE\n",
    "system.time(\n",
    "  svm.tune <- train(x=trainX,\n",
    "                    y= trainData$Class,\n",
    "                    method = \"svmRadial\",\n",
    "                    tuneLength = 9,\t\t\t\t\t# 9 values of the cost function\n",
    "                    preProc = c(\"center\",\"scale\"),\n",
    "                    metric=\"ROC\",\n",
    "                    trControl=ctrl)\t# same as for gbm above\n",
    ")\t\n",
    "\n",
    "svm.tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the SVM results   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(svm.tune,\n",
    "     metric=\"ROC\",\n",
    "     scales=list(x=list(log=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the test data with the SVM Model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm.pred <- predict(svm.tune,testX)\n",
    "head(svm.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusionMatrix(svm.pred,testData$Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm.probs <- predict(svm.tune,testX,type=\"prob\")\n",
    "head(svm.probs)\n",
    "\n",
    "svm.ROC <- roc(predictor=svm.probs$PS,\n",
    "               response=testData$Class,\n",
    "               levels=rev(levels(testData$Class)))\n",
    "svm.ROC\n",
    "\n",
    "plot(svm.ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST MODEL\n",
    "\n",
    "Now we'll also try to train a random Forest using the randomForest package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(randomForest)\n",
    "set.seed(seed_val)  # in case allowParallel = FALSE\n",
    "foreach(i = 1:getDoParWorkers()) %dopar% set.seed(worker_seeds[i]) # make sure things are repeatable in parallel\n",
    "ctrl$allowParallel\n",
    "system.time(rf.tune <-train(x=trainX,\n",
    "                y= trainData$Class,\n",
    "                method=\"rf\",\n",
    "                trControl= ctrl,\n",
    "                prox=TRUE,allowParallel=TRUE)\n",
    "            )\n",
    "rf.tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the Random Forest results\n",
    "plot(rf.tune,\n",
    "     metric=\"ROC\",\n",
    "     scales=list(x=list(log=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forest Predictions\n",
    "rf.pred <- predict(rf.tune,testX)\n",
    "head(rf.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusionMatrix(rf.pred,testData$Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.probs <- predict(rf.tune,testX,type=\"prob\")\n",
    "head(rf.probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.ROC <- roc(predictor=rf.probs$PS,\n",
    "               response=testData$Class,\n",
    "               levels=rev(levels(testData$Class)))\n",
    "rf.ROC\n",
    "\n",
    "plot(rf.ROC,main = \"Random Forest ROC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Multiple Models\n",
    "\n",
    "Having set the seeds to the same values before estimating each model, we have generated paired samples (See [Hothorn at al, \"The design and analysis of benchmark experiments-Journal of Computational and Graphical Statistics (2005) vol 14 (3) pp 675-699](http://statmath.wu-wien.ac.at/~zeileis/papers/Hothorn+Leisch+Zeileis-2005.pdf)). Note that we had to do this differently depending on whether the computational engine was parallel or not.\n",
    "\n",
    "Because of this, we are in a position to compare models using a resampling technique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rValues <- resamples(list(svm=svm.tune,gbm=gbm.tune,rf=rf.tune))\n",
    "rValues$values\n",
    "summary(rValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bwplot(rValues,metric=\"ROC\")\t\t    # boxplot\n",
    "dotplot(rValues,metric=\"ROC\")\t\t    # dotplot\n",
    "splom(rValues,metric=\"ROC\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "MR Client 3.2.2",
   "language": "R",
   "name": "irmrc32"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
